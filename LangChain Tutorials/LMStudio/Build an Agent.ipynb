{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monday, November 4, 2024\n",
    "\n",
    "mamba activate langchain\n",
    "\n",
    "[Build an Agent](https://python.langchain.com/docs/tutorials/agents/)\n",
    "\n",
    "The sample code uses Anthropic. To use it requires a paid plan, which is not by tokens but a monthly cost. So yeah, I am not gonna sign up for Anthropic because I think I will rarely use it, so I am going to switch to OpenAI in this code. \n",
    "\n",
    "Locally, I am using 'hermes-3-llama-3.1-8b' from LMStudio.\n",
    "\n",
    "This all runs without errors in one pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ[\"LANGCHAIN_TRACING_V2\"])\n",
    "print(os.environ[\"LANGCHAIN_API_KEY\"])\n",
    "print(os.environ[\"OPENAI_API_KEY\"])\n",
    "print(os.environ[\"TAVILY_API_KEY\"])\n",
    "print(os.environ[\"ANTHROPIC_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End-to-end agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant functionality\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "memory = MemorySaver()\n",
    "\n",
    "# just say no to Anthropic kids ... \n",
    "# model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "model = ChatOpenAI(base_url=\"http://localhost:1234/v1\", \n",
    "                   model = \"hermes-3-llama-3.1-8b\",  # do not pass in an unrecognized model name ... \n",
    "                   api_key=\"lm-studio\", \n",
    "                   temperature=0)\n",
    "\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello Bob! San Francisco is a great city to live in. What do you like most about living there? Are there any favorite spots or activities you enjoy in the city?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 18, 'total_tokens': 53, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'hermes-3-llama-3.1-8b', 'system_fingerprint': 'hermes-3-llama-3.1-8b', 'finish_reason': 'stop', 'logprobs': None}, id='run-5c6e537e-b029-47b8-9eb6-677f9b787060-0', usage_metadata={'input_tokens': 18, 'output_tokens': 35, 'total_tokens': 53})]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=\"I don't have real-time access to current weather data, but I can provide some general information for San Francisco:\\n\\nSan Francisco has a Mediterranean climate with cool, wet winters and mild, dry summers. On average, January is the coldest month with highs around 58¬∞F (14¬∞C) and lows near 43¬∞F (6¬∞C). July is typically the warmest month, with average high temperatures around 73¬∞F (23¬∞C) and lows around 55¬∞F (13¬∞C).\\n\\nHowever, weather can vary significantly from day to night and even within different neighborhoods in the city. It's not uncommon for San Francisco to experience microclimates where one part of the city could be foggy while another area is sunny.\\n\\nFor the most accurate current weather conditions and forecast in San Francisco, I recommend checking a reliable weather website or app like Weather.com, AccuWeather, or the National Weather Service.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 182, 'prompt_tokens': 71, 'total_tokens': 253, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'hermes-3-llama-3.1-8b', 'system_fingerprint': 'hermes-3-llama-3.1-8b', 'finish_reason': 'stop', 'logprobs': None}, id='run-1dc9b678-2424-40d0-bc58-c07af798af35-0', usage_metadata={'input_tokens': 71, 'output_tokens': 182, 'total_tokens': 253})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")\n",
    "\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1730742258, 'localtime': '2024-11-04 09:44'}, 'current': {'last_updated_epoch': 1730741400, 'last_updated': '2024-11-04 09:30', 'temp_c': 13.2, 'temp_f': 55.7, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 2.7, 'wind_kph': 4.3, 'wind_degree': 17, 'wind_dir': 'NNE', 'pressure_mb': 1023.0, 'pressure_in': 30.21, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 58, 'cloud': 0, 'feelslike_c': 13.0, 'feelslike_f': 55.4, 'windchill_c': 13.0, 'windchill_f': 55.4, 'heatindex_c': 13.2, 'heatindex_f': 55.7, 'dewpoint_c': 4.9, 'dewpoint_f': 40.7, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 1.0, 'gust_mph': 4.5, 'gust_kph': 7.2}}\"}, {'url': 'https://world-weather.info/forecast/usa/san_francisco/april-2024/', 'content': 'Hourly Week 10-Day 14-Day 30-Day Year. Detailed ‚ö° San Francisco Weather Forecast for April 2024 - day/night üå°Ô∏è temperatures, precipitations - World-Weather.info.'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "search_results = search.invoke(\"what is the weather in SF\")\n",
    "print(search_results)\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4\")\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! How can I assist you today? Feel free to ask me anything and I'll do my best to help or provide information on a wide range of topics.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today? Feel free to ask me anything and I'll do my best to help or provide information on a wide range of topics.\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: The weather in San Francisco, California can vary greatly depending on the time of year. Generally, San Francisco experiences cool summers and mild winters.\n",
      "\n",
      "As of my last update in April 2023, without a specific date or time provided, I can't give you an exact current weather report. However, here's a general idea:\n",
      "\n",
      "- **Summer (June to August)**: Temperatures typically range from the mid-50s to low 70s ¬∞F (around 10-21¬∞C). It's usually cooler and foggy near the coast, with warmer temperatures in inland areas.\n",
      "\n",
      "- **Winter (December to February)**: Temperatures can range from the upper 40s to low 60s ¬∞F (around 9-15¬∞C). Fog is common, especially during the night and early morning hours.\n",
      "\n",
      "Keep in mind that San Francisco's weather can be quite changeable, with microclimates across the city due to its unique geography. It's always a good idea to check a reliable weather forecast service for the most accurate and up-to-date information before planning your day.\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', id='fb42af81-d2ec-425b-b828-b9cc9a16de1e'),\n",
       " AIMessage(content=\"Hello! How can I assist you today? Feel free to ask me anything and I'll do my best to help or provide information on a wide range of topics.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 11, 'total_tokens': 44, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'hermes-3-llama-3.1-8b', 'system_fingerprint': 'hermes-3-llama-3.1-8b', 'finish_reason': 'stop', 'logprobs': None}, id='run-9a99f01b-1246-4d9b-a23c-bcc516592573-0', usage_metadata={'input_tokens': 11, 'output_tokens': 33, 'total_tokens': 44})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='whats the weather in sf?', id='6e239761-ce15-4f61-bd10-769cc2ece121'),\n",
       " AIMessage(content=\"To provide you with an accurate and up-to-date weather forecast for San Francisco, I would need to access a reliable weather service or API. However, I can give you a general idea of what to expect based on current trends.\\n\\nAs of March 2023, San Francisco's weather is typically mild and cool, especially considering its coastal location in Northern California. The city experiences a Mediterranean climate with warm, dry summers and cool, wet winters.\\n\\nIn the summer months (June-August), temperatures usually range from the mid-50s to low 70s Fahrenheit (around 12-21¬∞C). However, heatwaves can occasionally push temperatures into the high 80s F (around 29¬∞C) or above.\\n\\nDuring winter (December-February), temperatures are cooler and more variable, ranging from the low 40s to mid-60s F (around 4-18¬∞C). Rain is common during this season, with an average of about 3-5 inches (76-127 mm) per month. However, rainfall can be heavier or lighter than average at times.\\n\\nPlease note that these are general trends and actual weather conditions may vary. For the most accurate and current forecast, I recommend checking a reliable weather service or app specific to your needs.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 255, 'prompt_tokens': 16, 'total_tokens': 271, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'hermes-3-llama-3.1-8b', 'system_fingerprint': 'hermes-3-llama-3.1-8b', 'finish_reason': 'stop', 'logprobs': None}, id='run-977b5dc7-ddc6-48f3-acd1-0b152f71efc5-0', usage_metadata={'input_tokens': 16, 'output_tokens': 255, 'total_tokens': 271})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"To provide you with an accurate and up-to-date weather forecast for San Francisco, I would need to access a reliable weather service or API. However, I can give you a general idea of what to expect based on typical weather patterns in San Francisco.\\n\\nSan Francisco is known for its mild climate, but it can be quite variable depending on the time of year:\\n\\n1. Summer (June-August): Temperatures usually range from the mid-50s to low 70s Fahrenheit (around 10-21¬∞C). It's generally warm and dry, with occasional fog in the mornings or evenings.\\n\\n2. Fall (September-November): Temperatures start to cool down, ranging from the mid-50s to low 60s Fahrenheit (around 10-15¬∞C). Fog becomes more common, especially in the mornings.\\n\\n3. Winter (December-February): Temperatures are generally cool and damp, with averages ranging from the mid-40s to low 60s Fahrenheit (around 7-16¬∞C). Rain is more frequent during this season, but snow is extremely rare.\\n\\n4. Spring (March-May): Temperatures start to warm up again, ranging from the mid-50s to low 70s Fahrenheit (around 10-21¬∞C). Fog remains common, especially in the mornings.\\n\\nKeep in mind that these are general trends, and actual weather conditions can vary significantly depending on factors such as location within the city, time of day, and other atmospheric conditions. For the most accurate and current forecast, I recommend checking a reliable weather service or app specific to San Francisco.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 321, 'prompt_tokens': 16, 'total_tokens': 337, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'hermes-3-llama-3.1-8b', 'system_fingerprint': 'hermes-3-llama-3.1-8b', 'finish_reason': 'stop', 'logprobs': None}, id='run-f7ebef3b-b8dd-4cbf-a022-cfa93c851d51-0', usage_metadata={'input_tokens': 16, 'output_tokens': 321, 'total_tokens': 337})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To| provide| you| with| an| accurate| and| up|-to|-date|"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32886/2442860291.py:1: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  async for event in agent_executor.astream_events(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " weather| forecast| for| San| Francisco|,| I| would| need| to| access| a| reliable| weather| service| or| API|.| However|,| I| can| give| you| a| general| idea| of| what| to| expect| based| on| typical| weather| patterns| in| San| Francisco|.\n",
      "\n",
      "|San| Francisco| is| known| for| its| mild| climate|,| but| it| can| be| quite| variable| depending| on| the| time| of| year|:\n",
      "\n",
      "|1|.| Summer| (|June|-Aug|ust|):| Temper|atures| usually| range| from| the| mid|-|50|s| to| low| |70|s| Fahrenheit| (|around| |10|-|21|¬∞C|).| It|'s| generally| warm| and| dry|,| with| occasional| fog| in| the| mornings| or| evenings|.\n",
      "\n",
      "|2|.| Fall| (|September|-Nov|ember|):| Temper|atures| start| to| cool| down|,| ranging| from| the| mid|-|50|s| to| low| |60|s| Fahrenheit| (|around| |10|-|15|¬∞C|).| Fog| becomes| more| common|,| especially| in| the| mornings|.\n",
      "\n",
      "|3|.| Winter| (|December|-|February|):| Temper|atures| are| generally| cool| and| damp|,| with| averages| ranging| from| the| mid|-|40|s| to| low| |60|s| Fahrenheit| (|around| |7|-|16|¬∞C|).| Rain| is| more| frequent| during| this| season|,| but| snow| is| extremely| rare|.\n",
      "\n",
      "|4|.| Spring| (|March|-May|):| Temper|atures| start| to| warm| up| again|,| ranging| from| the| mid|-|50|s| to| low| |70|s| Fahrenheit| (|around| |10|-|21|¬∞C|).| Fog| remains| common|,| especially| in| the| mornings|.\n",
      "\n",
      "|Keep| in| mind| that| these| are| general| trends|,| and| actual| weather| conditions| can| vary| significantly| depending| on| factors| such| as| location| within| the| city|,| time| of| day|,| and| other| atmospheric| conditions|.| For| the| most| accurate| and| current| forecast|,| I| recommend| checking| a| reliable| weather| service| or| app| specific| to| San| Francisco|.|"
     ]
    }
   ],
   "source": [
    "async for event in agent_executor.astream_events(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}, version=\"v1\"\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"Hello Bob! It's nice to meet you. How can I assist you today? If you have any questions or need information on a particular topic, feel free to ask and I'll do my best to help you out.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 13, 'total_tokens': 58, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'hermes-3-llama-3.1-8b', 'system_fingerprint': 'hermes-3-llama-3.1-8b', 'finish_reason': 'stop', 'logprobs': None}, id='run-5e480a9c-2dd7-4ad7-aa9d-e6991c206399-0', usage_metadata={'input_tokens': 13, 'output_tokens': 45, 'total_tokens': 58})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Your name is Bob, as you mentioned in your initial greeting. Is there anything else I can help you with today, Bob?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 73, 'total_tokens': 99, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'hermes-3-llama-3.1-8b', 'system_fingerprint': 'hermes-3-llama-3.1-8b', 'finish_reason': 'stop', 'logprobs': None}, id='run-59ffe902-e1c0-4748-8d9e-f0f348a23fdd-0', usage_metadata={'input_tokens': 73, 'output_tokens': 26, 'total_tokens': 99})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"I do not have enough context to determine your name. If you would like me to call you by a specific name, please let me know and I will be happy to use it when referring to you in our conversation. Otherwise, you can simply provide me with your name whenever you'd like.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 14, 'total_tokens': 73, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'hermes-3-llama-3.1-8b', 'system_fingerprint': 'hermes-3-llama-3.1-8b', 'finish_reason': 'stop', 'logprobs': None}, id='run-2102c44e-bccb-41c2-b027-94824b12692c-0', usage_metadata={'input_tokens': 14, 'output_tokens': 59, 'total_tokens': 73})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
