{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuesday, November 5, 2024\n",
    "\n",
    "mamba activate langchain-chroma\n",
    "\n",
    "[Build a Local RAG Application](https://python.langchain.com/docs/tutorials/local_rag/)\n",
    "\n",
    "This notebook uses Ollama to serve up Llama 3.1 8b model. It can also run without errors with Llama 3.2 3b.\n",
    "\n",
    "This all runs in one pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    # model=\"llama3.1:8b\",\n",
    "       model=\"llama3.1:latest\",\n",
    "       #model=\"llama3.2:latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a simulated rap battle between Stephen Colbert and John Oliver:\n",
      "\n",
      "**The Scene:** A packed comedy club, with the audience cheering and chanting for more. Stephen Colbert and John Oliver take the stage, each confident in their own rhyming abilities.\n",
      "\n",
      "**Stephen Colbert (as Bored to Tears):**\n",
      "\n",
      "Yo, I'm Bored to Tears, the king of satire's throne\n",
      "My show's been a hit, since 2005, you know\n",
      "Daily Show, that's my claim to fame\n",
      "Making fun of idiots, that's just part of the game\n",
      "\n",
      "You think you're funny, John Oliver, but you're whack\n",
      "A British import, trying to take my spot back\n",
      "Last Week Tonight, sounds like a snooze fest too\n",
      "My audience is bigger, boo!\n",
      "\n",
      "**John Oliver (as The Truth Teller):**\n",
      "\n",
      "Hold up, Bored, let me set the record straight\n",
      "I'm The Truth Teller, here to bring the facts to the plate\n",
      "Your show's all jokes and no substance, it's true\n",
      "But I'm over here, exposing the lies that you're too afraid to pursue\n",
      "\n",
      "My show may not be as funny, but it's informative gold\n",
      "Exposing the scams, the cons, and the stories untold\n",
      "I've got the BBC behind me, that's some serious cred\n",
      "You're just a former comedian, trying to stay ahead!\n",
      "\n",
      "**Stephen Colbert (as Bored to Tears):**\n",
      "\n",
      "Informative gold? That's cute, John, real nice try\n",
      "But your show's all dry wit, no humor in sight\n",
      "My audience is loyal, we laugh and have fun\n",
      "Your viewers are bored, or so the ratings say, son\n",
      "\n",
      "And as for my past life as a comedian, well that's true\n",
      "But I'm a journalist now, breaking news to you\n",
      "I've got the best correspondents, like Robby the Robot too\n",
      "My show's not just funny, it's also accurate and new!\n",
      "\n",
      "**John Oliver (as The Truth Teller):**\n",
      "\n",
      "Accurate and new? That's rich coming from you\n",
      "A talk show host, who's all about comedy, that's true\n",
      "But when it comes to facts, I'm the one who brings the heat\n",
      "You're just a guy in a suit, making jokes to the street\n",
      "\n",
      "My show may not be as flashy, but it gets the job done\n",
      "I've taken on big topics, and made them fun for everyone\n",
      "And as for my audience, they're engaged, they're smart\n",
      "They know that comedy and journalism can be one, right from the start!\n",
      "\n",
      "**The Audience:** The crowd erupts in cheers and applause, unable to decide who won this epic rap battle. Both comedians take their final bows, grinning at each other with respect and a hint of rivalry.\n",
      "\n",
      "Note: This is just a simulated rap battle for entertainment purposes only. In reality, Stephen Colbert and John Oliver have both shown great respect and admiration for each other's work.\n"
     ]
    }
   ],
   "source": [
    "response_message = model.invoke(\n",
    "    \"Simulate a rap battle between Stephen Colbert and John Oliver\"\n",
    ")\n",
    "\n",
    "print(response_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main themes in these documents are:\\n\\n1. **Task Decomposition**: Breaking down complex tasks into smaller, manageable subgoals to facilitate efficient completion.\\n2. **Autonomous Agent System**: A system powered by Large Language Models (LLMs) that can perform planning, task execution, and reflection/refinement on complex tasks.\\n3. **Planning and Organization**: The importance of planning ahead and organizing tasks to ensure efficient handling of complex tasks.\\n\\nThese themes are related to the design of a LLM-powered autonomous agent system, which aims to facilitate the completion of complex tasks through decomposition, planning, and self-reflection.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | model | StrOutputParser()\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are three approaches to task decomposition: (1) using LLM with simple prompting, (2) employing task-specific instructions, and (3) incorporating human inputs. These methods enable breaking down complex tasks into manageable subgoals, facilitating efficient handling and planning. This process is crucial for agent systems powered by Large Language Models (LLM).'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=lambda input: format_docs(input[\"context\"]))\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "# Run\n",
    "chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q&A with retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition can be done through three approaches: (1) using Large Language Models (LLM) with simple prompting, (2) employing task-specific instructions, or (3) incorporating human inputs. These methods enable agents to break down complex tasks into smaller, manageable subgoals for efficient handling. This approach is part of the planning component in a LLM-powered autonomous agent system.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "qa_chain.invoke(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-chroma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
