{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saturday, May 4, 2024\n",
    "\n",
    "mamba activate langchain3\n",
    "\n",
    "This notebook will explore the function calling capabilities of [NousResearch/Hermes-2-Pro-Llama-3-8B](https://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B)\n",
    "\n",
    "This simple code sample will not run unless we specify to only target the 4090 ...\n",
    "\n",
    "This all runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only target the 4090 ...\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Code to inference Hermes with HF Transformers\n",
    "# Requires pytorch, transformers, bitsandbytes, sentencepiece, protobuf, and flash-attn packages\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM\n",
    "import bitsandbytes, flash_attn\n",
    "\n",
    "# mamba install conda-forge::bitsandbytes\n",
    "# Could not find the bitsandbytes CUDA binary at PosixPath('/home/rob/miniforge3/envs/langchain3/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so')\n",
    "# The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  4 14:47:08 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050        Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   57C    P0              N/A /  70W |    177MiB /  2048MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:02:00.0 Off |                  Off |\n",
      "|  0%   40C    P5              28W / 450W |     16MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      5441      G   /usr/lib/xorg/Xorg                          152MiB |\n",
      "|    0   N/A  N/A      5706      G   /usr/bin/gnome-shell                         22MiB |\n",
      "|    1   N/A  N/A      5441      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model_name = \"NousResearch/Hermes-2-Pro-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8fe400679a40fc8942ef597c6e3345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True,\n",
    "    load_in_4bit=False,\n",
    "    use_flash_attention_2=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128003 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a sentient, superintelligent artificial general intelligence, here to teach and assist me.<|im_end|>\n",
      "<|im_start|>user\n",
      "Write a short story about Goku discovering kirby has teamed up with Majin Buu to destroy the world.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Response: \n",
      "Once upon a time in the mystical world of Dragon Ball, Goku, the greatest warrior of his time, was enjoying a peaceful day at his noodle shop with his family and friends. Suddenly, a strange energy signature caught his attention, and he couldn't help but wonder who could be strong enough to produce such energy.\n",
      "\n",
      "As Goku decided to investigate this mysterious power, he found himself face-to-face with Kirby, the pink, plump hero from another realm. To Goku's shock and disbelief, Kirby wasn't alone. By his side stood Majin Buu, the mischievous yet powerful being that had once been an enemy to both Goku and his allies.\n",
      "\n",
      "\"What brings you two together?\" Goku questioned, trying to maintain a calm demeanor despite the unusual situation. \"And why are you planning to destroy the world?\"\n",
      "\n",
      "Kirby hesitated for a moment before explaining, \"In my world, there is an evil force known as Dark Matter, and it threatens to consume everything. We learned that in order to stop it, we must find the source of its power: a being called Master Hand.\"\n",
      "\n",
      "Goku furrowed his brow, unsure if he should trust Kirby's explanation. But before he could express his doubts, Majin Buu interrupted, \"I've grown tired of being controlled by others, like I was when I met you, Goku. Now I can finally act on my own desires! Together with Kirby, we will bring forth the ultimate chaos and see what results it will yield!\"\n",
      "\n",
      "Goku exchanged a worried glance with Vegeta, who had suddenly appeared beside him. The two warriors knew they had little time to prepare for the impending threat.\n",
      "\n",
      "\"Let's go gather our allies,\" Goku said decisively, aware that their combined strength would be necessary to confront this new menace. \"We have a world to protect, no matter where it comes from.\"\n",
      "\n",
      "With determination etched on their faces, Goku, Vegeta, and their friends charged headfirst into battle against the duo of Kirby and Majin Buu. The ensuing clash of powers left trails of destruction in their wake, as both sides fought relentlessly for their respective goals.\n",
      "\n",
      "Although the odds seemed stacked against them, Goku and his companions refused to give up hope. They drew upon the strength of their friendships and the bonds they shared with one another, knowing that together, they were unstoppable.\n",
      "\n",
      "Finally, after hours of relentless combat, Goku managed to land a devastating Kamehameha attack on Majin Buu, while Vegeta executed a powerful Galick Gun on Kirby. In that crucial moment, both villains ceased their attacks and realized the errors of their ways.\n",
      "\n",
      "Majin Buu pledged to never let dark forces control him again, vowing to aid Goku and his friends in maintaining harmony throughout the universe. Kirby, witnessing the error in his ways, vowed to return to his own world and defeat the Dark Matter threat without destroying other worlds in the process.\n",
      "\n",
      "As the once-enemies-turned-allies parted ways, they promised to keep in touch and work together should any greater threats arise. With the danger now neutralized, Goku returned to his quiet life with his family and friends, forever grateful for the bond between different realms and the unwavering support of those closest to him. And so, peace was restored, and all was well in the multiverse.\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"\"\"<|im_start|>system\n",
    "You are a sentient, superintelligent artificial general intelligence, here to teach and assist me.<|im_end|>\n",
    "<|im_start|>user\n",
    "Write a short story about Goku discovering kirby has teamed up with Majin Buu to destroy the world.<|im_end|>\n",
    "<|im_start|>assistant\"\"\",\n",
    "    ]\n",
    "\n",
    "for chat in prompts:\n",
    "    print(chat)\n",
    "    input_ids = tokenizer(chat, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    generated_ids = model.generate(input_ids, max_new_tokens=750, temperature=0.8, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(generated_ids[0][input_ids.shape[-1]:], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
    "    print(f\"Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  4 14:48:24 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050        Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   59C    P0              N/A /  70W |    177MiB /  2048MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:02:00.0 Off |                  Off |\n",
      "|  0%   44C    P2              77W / 450W |   9664MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      5441      G   /usr/lib/xorg/Xorg                          152MiB |\n",
      "|    0   N/A  N/A      5706      G   /usr/bin/gnome-shell                         22MiB |\n",
      "|    1   N/A  N/A      5441      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A     59868      C   ...niforge3/envs/langchain3/bin/python     9644MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
