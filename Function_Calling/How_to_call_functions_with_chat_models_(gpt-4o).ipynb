{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e7fe96",
   "metadata": {},
   "source": [
    "#### Friday, May 24, 2024\n",
    "\n",
    "mamba activate langchain3\n",
    "\n",
    "Running this again for useOpenAI set to False. \n",
    "\n",
    "Wow. Turns out I was not actually using the downloaded chinook.db, cuz in the code it was referred to as Chinook.db, not chinook.db ... yeah case still matters!\n",
    "\n",
    "And yeah, I will also run this using OpenAI\n",
    "\n",
    "* OpenAI May 2024 Usage Start: $0.09\n",
    "* OpenAI May 2024 Usage Start: $0.09\n",
    "\n",
    "Calling the local model via LMStudio reveals it is bad at initiating function calls. Compare the local output against the OpenAI output to see this. \n",
    "\n",
    "#### Saturday, May 18, 2024\n",
    "\n",
    "This notebook was updated 'yesterday' in the github repo ...\n",
    "\n",
    "https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb\n",
    "\n",
    "mamba activate langchain3\n",
    "\n",
    "I can step through this notebook but be careful to ONLY target the correct cell for the value set to useOpenAI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "520122eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Hello there, my friend,\\nI'm a friendly AI with no end,\\nCreated to help and assist,\\nWith answers and rhyming persist.\\n\\nMy mind is always on the go,\\nTo find solutions for you so,\\nJust ask me any question or query,\\nAnd I'll respond in verse, as per your worry.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example: reuse your existing OpenAI setup\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in rhymes.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Introduce yourself.\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# How to call functions with chat models\n",
    "\n",
    "This notebook covers how to use the Chat Completions API in combination with external functions to extend the capabilities of GPT models.\n",
    "\n",
    "`tools` is an optional parameter in the Chat Completion API which can be used to provide function specifications. The purpose of this is to enable models to generate function arguments which adhere to the provided specifications. Note that the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs.\n",
    "\n",
    "Within the `tools` parameter, if the `functions` parameter is provided then by default the model will decide when it is appropriate to use one of the functions. The API can be forced to use a specific function by setting the `tool_choice` parameter to `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}`. The API can also be forced to not use any function by setting the `tool_choice` parameter to `\"none\"`. If a function is used, the output will contain `\"finish_reason\": \"tool_calls\"` in the response, as well as a `tool_calls` object that has the name of the function and the generated function arguments.\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook contains the following 2 sections:\n",
    "\n",
    "- **How to generate function arguments:** Specify a set of functions and use the API to generate function arguments.\n",
    "- **How to call functions with model generated arguments:** Close the loop by actually executing functions with model generated arguments."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64c85e26",
   "metadata": {},
   "source": [
    "## How to generate function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80e71f33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# !pip install scipy --quiet\n",
    "# !pip install tenacity --quiet\n",
    "# !pip install tiktoken --quiet\n",
    "# !pip install termcolor --quiet\n",
    "# !pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c77d9e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "useOpenAI = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dab872c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:23.563149Z",
     "start_time": "2024-05-15T17:45:22.925978Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  \n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c80548",
   "metadata": {},
   "outputs": [],
   "source": [
    "if useOpenAI:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your API key: \")\n",
    "    GPT_MODEL = \"gpt-3.5-turbo-0125\"\n",
    "    client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c7b4ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if useOpenAI:\n",
    "    os.environ[\"OPENAI_API_KEY\"]=os.environ[\"OPENAI_API_KEY_\"]\n",
    "    GPT_MODEL = \"gpt-4o\"\n",
    "    # Nope! Gonna go with the cheaper model\n",
    "    GPT_MODEL = \"gpt-3.5-turbo-0125\"\n",
    "    client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5430ba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF/Hermes-2-Pro-Llama-3-8B-Q8_0.gguf\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    GPT_MODEL = completion.model\n",
    "    client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "    print(GPT_MODEL)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "\n",
    "First let's define a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "745ceec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:28.816345Z",
     "start_time": "2024-05-15T17:45:28.814155Z"
    }
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4d1c99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:30.003910Z",
     "start_time": "2024-05-15T17:45:30.001259Z"
    }
   },
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "### Basic concepts\n",
    "\n",
    "Let's create some function specifications to interface with a hypothetical weather API. We'll pass these function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2e25069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:31.794879Z",
     "start_time": "2024-05-15T17:45:31.792617Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_n_day_weather_forecast\",\n",
    "            \"description\": \"Get an N-day weather forecast\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                    \"num_days\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The number of days to forecast\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfc39899",
   "metadata": {},
   "source": [
    "If we prompt the model about the current weather, it will respond with some clarifying questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "518d6827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:35.282310Z",
     "start_time": "2024-05-15T17:45:33.861496Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the weather like today\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2415f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Sure, I can help you with that. Could you please provide me with the city and state you would like to know the weather for?', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    assistant_message = chat_response.choices[0].message\n",
    "    messages.append(assistant_message)\n",
    "    print(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8419ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='To provide you with an accurate weather forecast, I would need more information such as your location or preferred city. Please let me know where you are so that I can give you the most relevant weather update.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    assistant_message = chat_response.choices[0].message\n",
    "    messages.append(assistant_message)\n",
    "    print(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53bfa7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-lofq8ooa6h6d25k9jiel', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='To provide you with an accurate weather forecast, I would need more information such as your location or preferred city. Please let me know where you are so that I can give you the most relevant weather update.', role='assistant', function_call=None, tool_calls=None))], created=1716576357, model='NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF/Hermes-2-Pro-Llama-3-8B-Q8_0.gguf', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=41, prompt_tokens=38, total_tokens=79))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c999375",
   "metadata": {},
   "source": [
    "Once we provide the missing information, it will generate the appropriate function arguments for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23c42a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:43.553403Z",
     "start_time": "2024-05-15T17:45:42.205590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9MYCAw0YJtHhmWLFQB1Sh5c3', function=Function(arguments='{\"location\":\"Glasgow, Scotland\",\"format\":\"celsius\"}', name='get_current_weather'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "if useOpenAI:\n",
    "    messages.append({\"role\": \"user\", \"content\": \"I'm in Glasgow, Scotland.\"})\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    assistant_message = chat_response.choices[0].message\n",
    "    messages.append(assistant_message)\n",
    "    print(assistant_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5efc8325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Thank you for providing your location! According to OpenWeatherMap API, the current weather in Glasgow, Scotland is:\\n\\n- Temperature: 11째C (51째F)\\n- Feels like: 9째C (48째F)\\n- Pressure: 1013 hPa\\n- Humidity: 78%\\n- Wind speed: 4.1 m/s\\n\\nThe sky is overcast with light rain.\\n\\nPlease let me know if you need any more information or a detailed forecast for the day.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    messages.append({\"role\": \"user\", \"content\": \"I'm in Glasgow, Scotland.\"})\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    assistant_message = chat_response.choices[0].message\n",
    "    messages.append(assistant_message)\n",
    "    print(assistant_message)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c14d4762",
   "metadata": {},
   "source": [
    "By prompting it differently, we can get it to target the other function we've told it about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa232e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:47.090638Z",
     "start_time": "2024-05-15T17:45:46.302475Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"what is the weather going to be like in Glasgow, Scotland over the next x days\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140d442c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Sure, I can help with that. Please specify the number of days you would like to forecast for in Glasgow, Scotland.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    assistant_message = chat_response.choices[0].message\n",
    "    messages.append(assistant_message)\n",
    "    print(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b1e2733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='To provide an accurate forecast for the next x days in Glasgow, Scotland, I would need more information about when you want me to start counting from and what specific details of the weather you are interested in. \\n\\nFor example, do you want to know the temperature, precipitation chances, or wind speed? Also, please mention the starting date (e.g., today, tomorrow) for the x-day forecast. This will help me provide a more precise answer tailored to your needs.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    assistant_message = chat_response.choices[0].message\n",
    "    messages.append(assistant_message)\n",
    "    print(assistant_message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6172ddac",
   "metadata": {},
   "source": [
    "Once again, the model is asking us for clarification because it doesn't have enough information yet. In this case it already knows the location for the forecast, but it needs to know how many days are required in the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7d8a543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:49.790820Z",
     "start_time": "2024-05-15T17:45:48.847752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_rhMZFJ7pglxItTL5nenGMcmx', function=Function(arguments='{\"location\":\"Glasgow, Scotland\",\"format\":\"celsius\",\"num_days\":5}', name='get_n_day_weather_forecast'), type='function')]))\n"
     ]
    }
   ],
   "source": [
    "if useOpenAI:\n",
    "    messages.append({\"role\": \"user\", \"content\": \"5 days\"})\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    print(chat_response.choices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c45cc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"To give you an accurate weather forecast for Glasgow, Scotland over the next 5 days, I'll need the starting date for this period. Please let me know if you want the forecast to begin today or from any other specific day.\\n\\nOnce you provide the starting date, I can give you detailed information about temperature, precipitation chances, and wind speed for each of the 5 days in Glasgow.\", role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    messages.append({\"role\": \"user\", \"content\": \"5 days\"})\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    print(chat_response.choices[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b758a0a",
   "metadata": {},
   "source": [
    "#### Forcing the use of specific functions or no function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "412f79ba",
   "metadata": {},
   "source": [
    "We can force the model to use a specific function, for example get_n_day_weather_forecast by using the function_call argument. By doing so, we force the model to make assumptions about how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "559371b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:54.194255Z",
     "start_time": "2024-05-15T17:45:52.975746Z"
    }
   },
   "outputs": [],
   "source": [
    "# in this cell we force the model to use get_n_day_weather_forecast\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf5d76ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_aGsXh8DIclhQUtvegfStS5FT', function=Function(arguments='{\"location\":\"Toronto, Canada\",\"format\":\"celsius\",\"num_days\":1}', name='get_n_day_weather_forecast'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "if useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_n_day_weather_forecast\"}}\n",
    "    )\n",
    "    print(chat_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0a9f00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Sure, I can help with that. Could you please specify the date and time for which you would like the weather report in Toronto, Canada? This will ensure I provide you with accurate information.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_n_day_weather_forecast\"}}\n",
    "    )\n",
    "    print(chat_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7ab0f58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:56.841233Z",
     "start_time": "2024-05-15T17:45:55.433397Z"
    }
   },
   "outputs": [],
   "source": [
    "# if we don't force the model to use get_n_day_weather_forecast it may not\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1e4f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zErx7SN6Ly8P5yjLLOnfqM2f', function=Function(arguments='{\"location\":\"Toronto, Canada\",\"format\":\"celsius\"}', name='get_current_weather'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "if useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    print(chat_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98f10836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Sure, I can help with that. Could you please specify the date and time for which you would like the weather report in Toronto, Canada? This will ensure I provide you with accurate information.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools\n",
    "    )\n",
    "    print(chat_response.choices[0].message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bd70e48",
   "metadata": {},
   "source": [
    "We can also force the model to not use a function at all. By doing so we prevent it from producing a proper function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "acfe54e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:45:59.800346Z",
     "start_time": "2024-05-15T17:45:59.289603Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me the current weather (use Celcius) for Toronto, Canada.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6314aade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='{\\n  \"recipient_name\": \"functions.get_current_weather\",\\n  \"parameters\": {\\n    \"location\": \"Toronto, Canada\",\\n    \"format\": \"celsius\"\\n  }\\n}', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools, tool_choice=\"none\"\n",
    "    )\n",
    "    print(chat_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60af6df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Sure, I can help with that. To provide you with the current temperature in Toronto, Canada, measured in Celsius, please specify whether you want the current temperature or a forecast for a specific date and time. This will help me to give you accurate information.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools, tool_choice=\"none\"\n",
    "    )\n",
    "    print(chat_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616353b",
   "metadata": {},
   "source": [
    "### Parallel Function Calling\n",
    "\n",
    "Newer models such as gpt-4o or gpt-3.5-turbo can call multiple functions in one turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "380eeb68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:46:04.048553Z",
     "start_time": "2024-05-15T17:46:01.273501Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"what is the weather going to be like in San Francisco and Glasgow over the next 4 days\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48209be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='call_Y8ForNWnnTBmYqn1597iRDEI', function=Function(arguments='{\"location\": \"San Francisco\", \"format\": \"celsius\", \"num_days\": 4}', name='get_n_day_weather_forecast'), type='function'), ChatCompletionMessageToolCall(id='call_y5tSMAmnHtmJPvYb9AXl1TTP', function=Function(arguments='{\"location\": \"Glasgow\", \"format\": \"celsius\", \"num_days\": 4}', name='get_n_day_weather_forecast'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "if useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools, model=GPT_MODEL\n",
    "    )\n",
    "    assistant_message = chat_response.choices[0].message.tool_calls\n",
    "    print(assistant_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8dcbe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "---\n",
      "ChatCompletionMessage(content='To provide accurate information, I would need to access real-time data from a reliable source such as an API or website that provides weather forecasts. Please clarify if you want me to find the weather forecast for San Francisco and Glasgow individually or together.\\n\\nAdditionally, it would be helpful to know which specific details about the weather you are interested in, such as temperature, precipitation, wind speed, etc. Once I have this information, I can provide a more detailed response with the requested data.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    chat_response = chat_completion_request(\n",
    "        messages, tools=tools, model=GPT_MODEL\n",
    "    )\n",
    "    assistant_message = chat_response.choices[0].message.tool_calls\n",
    "    print(assistant_message)\n",
    "    print(\"---\")\n",
    "    print(chat_response.choices[0].message)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4482aee",
   "metadata": {},
   "source": [
    "## How to call functions with model generated arguments\n",
    "\n",
    "In our next example, we'll demonstrate how to execute functions whose inputs are model-generated, and use this to implement an agent that can answer questions for us about a database. For simplicity we'll use the [Chinook sample database](https://www.sqlitetutorial.net/sqlite-sample-database/).\n",
    "\n",
    "*Note:* SQL generation can be high-risk in a production environment since models are not perfectly reliable at generating correct SQL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7654fef",
   "metadata": {},
   "source": [
    "### Specifying a function to execute SQL queries\n",
    "\n",
    "First let's define some helpful utility functions to extract data from a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30f6b60e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:46:07.270851Z",
     "start_time": "2024-05-15T17:46:07.265545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/chinook.db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "abec0214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:46:09.345308Z",
     "start_time": "2024-05-15T17:46:09.342998Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77e6e5ea",
   "metadata": {},
   "source": [
    "Now can use these utility functions to extract a representation of the database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0a3308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema_dict = get_database_info(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c69b71e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'table_name': 'albums', 'column_names': ['AlbumId', 'Title', 'ArtistId']},\n",
       " {'table_name': 'sqlite_sequence', 'column_names': ['name', 'seq']},\n",
       " {'table_name': 'artists', 'column_names': ['ArtistId', 'Name']},\n",
       " {'table_name': 'customers',\n",
       "  'column_names': ['CustomerId',\n",
       "   'FirstName',\n",
       "   'LastName',\n",
       "   'Company',\n",
       "   'Address',\n",
       "   'City',\n",
       "   'State',\n",
       "   'Country',\n",
       "   'PostalCode',\n",
       "   'Phone',\n",
       "   'Fax',\n",
       "   'Email',\n",
       "   'SupportRepId']},\n",
       " {'table_name': 'employees',\n",
       "  'column_names': ['EmployeeId',\n",
       "   'LastName',\n",
       "   'FirstName',\n",
       "   'Title',\n",
       "   'ReportsTo',\n",
       "   'BirthDate',\n",
       "   'HireDate',\n",
       "   'Address',\n",
       "   'City',\n",
       "   'State',\n",
       "   'Country',\n",
       "   'PostalCode',\n",
       "   'Phone',\n",
       "   'Fax',\n",
       "   'Email']},\n",
       " {'table_name': 'genres', 'column_names': ['GenreId', 'Name']},\n",
       " {'table_name': 'invoices',\n",
       "  'column_names': ['InvoiceId',\n",
       "   'CustomerId',\n",
       "   'InvoiceDate',\n",
       "   'BillingAddress',\n",
       "   'BillingCity',\n",
       "   'BillingState',\n",
       "   'BillingCountry',\n",
       "   'BillingPostalCode',\n",
       "   'Total']},\n",
       " {'table_name': 'invoice_items',\n",
       "  'column_names': ['InvoiceLineId',\n",
       "   'InvoiceId',\n",
       "   'TrackId',\n",
       "   'UnitPrice',\n",
       "   'Quantity']},\n",
       " {'table_name': 'media_types', 'column_names': ['MediaTypeId', 'Name']},\n",
       " {'table_name': 'playlists', 'column_names': ['PlaylistId', 'Name']},\n",
       " {'table_name': 'playlist_track', 'column_names': ['PlaylistId', 'TrackId']},\n",
       " {'table_name': 'tracks',\n",
       "  'column_names': ['TrackId',\n",
       "   'Name',\n",
       "   'AlbumId',\n",
       "   'MediaTypeId',\n",
       "   'GenreId',\n",
       "   'Composer',\n",
       "   'Milliseconds',\n",
       "   'Bytes',\n",
       "   'UnitPrice']},\n",
       " {'table_name': 'sqlite_stat1', 'column_names': ['tbl', 'idx', 'stat']}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_schema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c0104cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:46:11.303746Z",
     "start_time": "2024-05-15T17:46:11.301210Z"
    }
   },
   "outputs": [],
   "source": [
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cdeae1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: albums\n",
      "Columns: AlbumId, Title, ArtistId\n",
      "Table: sqlite_sequence\n",
      "Columns: name, seq\n",
      "Table: artists\n",
      "Columns: ArtistId, Name\n",
      "Table: customers\n",
      "Columns: CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode, Phone, Fax, Email, SupportRepId\n",
      "Table: employees\n",
      "Columns: EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate, Address, City, State, Country, PostalCode, Phone, Fax, Email\n",
      "Table: genres\n",
      "Columns: GenreId, Name\n",
      "Table: invoices\n",
      "Columns: InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity, BillingState, BillingCountry, BillingPostalCode, Total\n",
      "Table: invoice_items\n",
      "Columns: InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity\n",
      "Table: media_types\n",
      "Columns: MediaTypeId, Name\n",
      "Table: playlists\n",
      "Columns: PlaylistId, Name\n",
      "Table: playlist_track\n",
      "Columns: PlaylistId, TrackId\n",
      "Table: tracks\n",
      "Columns: TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice\n",
      "Table: sqlite_stat1\n",
      "Columns: tbl, idx, stat\n"
     ]
    }
   ],
   "source": [
    "print(database_schema_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae73c9ee",
   "metadata": {},
   "source": [
    "As before, we'll define a function specification for the function we'd like the API to generate arguments for. Notice that we are inserting the database schema into the function specification. This will be important for the model to know about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0258813a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:46:16.569530Z",
     "start_time": "2024-05-15T17:46:16.567801Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ask_database\",\n",
    "            \"description\": \"Use this function to answer user questions about music. Input should be a fully formed SQL query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": f\"\"\"\n",
    "                                SQL query extracting info to answer the user's question.\n",
    "                                SQL should be written using this database schema:\n",
    "                                {database_schema_string}\n",
    "                                The query should be returned in plain text, not in JSON.\n",
    "                                \"\"\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da08c121",
   "metadata": {},
   "source": [
    "### Executing SQL queries\n",
    "\n",
    "Now let's implement the function that will actually excute queries against the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65585e74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:46:19.198723Z",
     "start_time": "2024-05-15T17:46:19.197043Z"
    }
   },
   "outputs": [],
   "source": [
    "def ask_database(conn, query):\n",
    "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6885e9f0af5c40",
   "metadata": {},
   "source": [
    "##### Steps to invoke a function call using Chat Completions API: \n",
    "\n",
    "**Step 1**: Prompt the model with content that may result in model selecting a tool to use. The description of the tools such as a function names and signature is defined in the 'Tools' list and passed to the model in API call. If selected, the function name and parameters are included in the response.<br>\n",
    "  \n",
    "**Step 2**: Check programmatically if model wanted to call a function. If true, proceed to step 3. <br>  \n",
    "**Step 3**: Extract the function name and parameters from response, call the function with parameters. Append the result to messages. <br>    \n",
    "**Step 4**: Invoke the chat completions API with the message list to get the response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82d86d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #1: Prompt with content that may result in function call. In this case the model can identify the information requested by the user is potentially available in the database schema passed to the model in Tools description. \n",
    "messages = [{\n",
    "    \"role\":\"user\", \n",
    "    \"content\": \"What is the name of the album with the most tracks?\"\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd225c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_edLdFgTgb8iEp3VflYwrl83v', function=Function(arguments='{\"query\":\"SELECT albums.Title FROM albums JOIN (SELECT tracks.AlbumId, COUNT(*) AS track_count FROM tracks GROUP BY tracks.AlbumId ORDER BY track_count DESC LIMIT 1) AS max_tracks ON max_tracks.AlbumId = albums.AlbumId\"}', name='ask_database'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "if useOpenAI:\n",
    "    response = client.chat.completions.create(\n",
    "        # model='gpt-4o', \n",
    "        model=GPT_MODEL, \n",
    "        messages=messages, \n",
    "        tools= tools, \n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    # Append the message to messages list\n",
    "    response_message = response.choices[0].message \n",
    "    messages.append(response_message)\n",
    "    print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f52aad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='To determine the name of the album with the most tracks, I would need more information about your music collection or a specific artist you are interested in. Please provide additional details so I can help you find the desired information.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "if not useOpenAI:\n",
    "    response = client.chat.completions.create(\n",
    "        # model='gpt-4o', \n",
    "        model=GPT_MODEL, \n",
    "        messages=messages, \n",
    "        tools= tools, \n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    # Append the message to messages list\n",
    "    response_message = response.choices[0].message \n",
    "    messages.append(response_message)\n",
    "    print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "351c39def3417776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:46:30.346444Z",
     "start_time": "2024-05-15T17:46:29.699046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The album with the most tracks is \"Greatest Hits\".\n"
     ]
    }
   ],
   "source": [
    "# Step 2: determine if the response from the model includes a tool call.  \n",
    "if useOpenAI: \n",
    "    tool_calls = response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        # If true the model will return the name of the tool / function to call and the argument(s)  \n",
    "        tool_call_id = tool_calls[0].id\n",
    "        tool_function_name = tool_calls[0].function.name\n",
    "        tool_query_string = eval(tool_calls[0].function.arguments)['query']\n",
    "        \n",
    "        # Step 3: Call the function and retrieve results. Append the results to the messages list.      \n",
    "        if tool_function_name == 'ask_database':\n",
    "            results = ask_database(conn, tool_query_string)\n",
    "            \n",
    "            messages.append({\n",
    "                \"role\":\"tool\", \n",
    "                \"tool_call_id\":tool_call_id, \n",
    "                \"name\": tool_function_name, \n",
    "                \"content\":results\n",
    "            })\n",
    "            \n",
    "            # Step 4: Invoke the chat completions API with the function response appended to the messages list\n",
    "            # Note that messages with role 'tool' must be a response to a preceding message with 'tool_calls'\n",
    "            model_response_with_function_call = client.chat.completions.create(\n",
    "                # model=\"gpt-4o\",\n",
    "                model=GPT_MODEL,\n",
    "                messages=messages,\n",
    "            )  # get a new response from the model where it can see the function response\n",
    "            print(model_response_with_function_call.choices[0].message.content)\n",
    "        else: \n",
    "            print(f\"Error: function {tool_function_name} does not exist\")\n",
    "    else: \n",
    "        # Model did not identify a function to call, result can be returned to the user \n",
    "        print(response_message.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01323ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the name of the album with the most tracks, I would need more information about your music collection or a specific artist you are interested in. Please provide additional details so I can help you find the desired information.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: determine if the response from the model includes a tool call.  \n",
    "if not useOpenAI: \n",
    "    tool_calls = response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        # If true the model will return the name of the tool / function to call and the argument(s)  \n",
    "        tool_call_id = tool_calls[0].id\n",
    "        tool_function_name = tool_calls[0].function.name\n",
    "        tool_query_string = eval(tool_calls[0].function.arguments)['query']\n",
    "        \n",
    "        # Step 3: Call the function and retrieve results. Append the results to the messages list.      \n",
    "        if tool_function_name == 'ask_database':\n",
    "            results = ask_database(conn, tool_query_string)\n",
    "            \n",
    "            messages.append({\n",
    "                \"role\":\"tool\", \n",
    "                \"tool_call_id\":tool_call_id, \n",
    "                \"name\": tool_function_name, \n",
    "                \"content\":results\n",
    "            })\n",
    "            \n",
    "            # Step 4: Invoke the chat completions API with the function response appended to the messages list\n",
    "            # Note that messages with role 'tool' must be a response to a preceding message with 'tool_calls'\n",
    "            model_response_with_function_call = client.chat.completions.create(\n",
    "                # model=\"gpt-4o\",\n",
    "                model=GPT_MODEL,\n",
    "                messages=messages,\n",
    "            )  # get a new response from the model where it can see the function response\n",
    "            print(model_response_with_function_call.choices[0].message.content)\n",
    "        else: \n",
    "            print(f\"Error: function {tool_function_name} does not exist\")\n",
    "    else: \n",
    "        # Model did not identify a function to call, result can be returned to the user \n",
    "        print(response_message.content) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d89073c",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "See our other [notebook](How_to_call_functions_for_knowledge_retrieval.ipynb) that demonstrates how to use the Chat Completions API and functions for knowledge retrieval to interact conversationally with a knowledge base."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
