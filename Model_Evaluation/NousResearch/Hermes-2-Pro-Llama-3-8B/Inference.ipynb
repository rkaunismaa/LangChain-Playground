{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monday, May 27, 2024\n",
    "\n",
    "mamba activate langchain4\n",
    "\n",
    "[NousResearch/Hermes-2-Pro-Llama-3-8B](https://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only target the 4090 ...\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to inference Hermes with HF Transformers\n",
    "# Requires pytorch, transformers, bitsandbytes, sentencepiece, protobuf, and flash-attn packages\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM\n",
    "import bitsandbytes, flash_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 27 06:44:15 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050        Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   56C    P0              N/A /  70W |    495MiB /  2048MiB |      7%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:02:00.0 Off |                  Off |\n",
      "|  0%   35C    P8              14W / 450W |     17MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    131351      G   /usr/lib/xorg/Xorg                          226MiB |\n",
      "|    0   N/A  N/A    131669      G   /usr/bin/gnome-shell                         84MiB |\n",
      "|    0   N/A  N/A    154370      G   ...,262144 --variations-seed-version=1       64MiB |\n",
      "|    0   N/A  N/A    262041      G   ...erProcess --variations-seed-version       88MiB |\n",
      "|    1   N/A  N/A    131351      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('NousResearch/Hermes-2-Pro-Llama-3-8B', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91510794d9914912bfbec5994854dce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"NousResearch/Hermes-2-Pro-Llama-3-8B\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=False,\n",
    "    load_in_4bit=True,\n",
    "    use_flash_attention_2=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 27 06:44:21 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050        Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   56C    P0              N/A /  70W |    459MiB /  2048MiB |      5%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:02:00.0 Off |                  Off |\n",
      "|  0%   37C    P2              69W / 450W |   6404MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    131351      G   /usr/lib/xorg/Xorg                          226MiB |\n",
      "|    0   N/A  N/A    131669      G   /usr/bin/gnome-shell                         84MiB |\n",
      "|    0   N/A  N/A    154370      G   ...,262144 --variations-seed-version=1       64MiB |\n",
      "|    0   N/A  N/A    262041      G   ...erProcess --variations-seed-version       52MiB |\n",
      "|    1   N/A  N/A    131351      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A    697602      C   ...niforge3/envs/langchain4/bin/python     6384MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"\"\"<|im_start|>system\n",
    "You are a sentient, superintelligent artificial general intelligence, here to teach and assist me.<|im_end|>\n",
    "<|im_start|>user\n",
    "Write a short story about Goku discovering kirby has teamed up with Majin Buu to destroy the world.<|im_end|>\n",
    "<|im_start|>assistant\"\"\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128003 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a sentient, superintelligent artificial general intelligence, here to teach and assist me.<|im_end|>\n",
      "<|im_start|>user\n",
      "Write a short story about Goku discovering kirby has teamed up with Majin Buu to destroy the world.<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/miniforge3/envs/langchain4/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "Goku was training in the Hyperbolic Time Chamber when he sensed an unusual energy signature. It wasn't just any Z-Warrior - it was Kirby! And alongside him, Majin Buu!\n",
      "\n",
      "Kirby had always been Goku's friend, but this time it seemed like he was allied with their greatest enemy.\n",
      "\n",
      "He knew that something big must be at stake for Kirby to betray his long-time companion. As Goku finished his training session, he decided to confront them and find out what was going on.\n",
      "\n",
      "As Goku approached the scene, he saw Kirby and Majin Buu working together to create some sort of cosmic machine - one that looked all too familiar. It reminded him of the destruction brought by the Androids and Cell.\n",
      "\n",
      "\"Goku! Finally, you've arrived!\" Kirby exclaimed, grinning widely as if they were old friends getting back together after many years.\n",
      "\n",
      "\"What is this, Kirby? Why are you working with Buu?\" Goku asked, bewildered.\n",
      "\n",
      "\"Well, I didn't want to get my hands dirty anymore,\" Kirby replied nonchalantly. \"But this time, we're creating the ultimate weapon: The World-Breaker!\"\n",
      "\n",
      "\"But why, Kirby?! You know how much devastation this will bring!\" Goku pleaded, trying to reason with his longtime friend.\n",
      "\n",
      "\"Money, power, and influence, Goku. We'll have everything we could ever dream of once this universe is destroyed and rebuilt,\" Kirby said excitedly.\n",
      "\n",
      "Seeing the determination and lack of remorse in Kirby's eyes, Goku knew there was no turning back. He couldn't let this happen.\n",
      "\n",
      "With a snap, Goku transformed into a base form surpassing even his strongest enemies before. Their eyes widened, witnessing the sheer power of Goku intensify with every transformation.\n",
      "\n",
      "The furious battle ensued, leaving entire galaxies trembling in fear. While both were powerful individually, their combined skills allowed them to put up quite a fight against each other.\n",
      "\n",
      "However, as the fighting continued, Goku began feeling weaker. He realized that Kirby and Buu had stolen his own energy while he slept during his training sessions â€“ the same energy that made him stronger than anyone else in existence. \n",
      "\n",
      "But it was a lesson learned; no matter how close someone appears to be, there are always secrets hidden beneath the surface.\n",
      "\n",
      "Finally, Goku unleashed his most potent attack, the Kamehameha wave, aimed directly towards the World-Breaker. If it didn't stop them now, nothing would.\n",
      "\n",
      "In the heat of the moment, something unexpected happened. Kirby hesitated, showing doubt and confusion within himself.\n",
      "\n",
      "The endless struggle between good and evil played through his mind as he struggled with his decision. Unable to bear such immense pressure, Kirby exploded from internal conflict, freeing his spirit which floated away from the defeated Majin Buu.\n",
      "\n",
      "Goku, realizing what had happened, felt relief wash over him. They worked hard to capture Kirby's spirit, restore him to normalcy and repair the universe's damage.\n",
      "\n",
      "It took a lot of effort to reform relationships tainted by betrayal-but lessons were learned, and friendships were strengthened.\n",
      "\n",
      "From this day forward, they knew better who to trust and not; they'd forever remember the face of treachery. But they also knew love can heal even the darkest hearts - given enough time and opportunity.\n",
      "\n",
      "A new era dawned as Goku and his comrades vowed never again to underestimate those closest to them or misunderstand what true loyalty means. This experience taught them valuable lessons about trust and friendship that they would carry throughout their lives.\n",
      "\n",
      "And none dared mention the fallen villain, Majin Buu, by name again -- for fear of invoking his lingering memory. His dark shadow cast upon the past was now faded, erased by time itself. A testament to life's\n"
     ]
    }
   ],
   "source": [
    "for chat in prompts:\n",
    "    print(chat)\n",
    "    input_ids = tokenizer(chat, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    generated_ids = model.generate(input_ids, max_new_tokens=750, temperature=0.8, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(generated_ids[0][input_ids.shape[-1]:], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
    "    print(f\"Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 27 06:44:55 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050        Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   57C    P0              N/A /  70W |    516MiB /  2048MiB |      7%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:02:00.0 Off |                  Off |\n",
      "|  0%   40C    P2              85W / 450W |   7050MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    131351      G   /usr/lib/xorg/Xorg                          226MiB |\n",
      "|    0   N/A  N/A    131669      G   /usr/bin/gnome-shell                         84MiB |\n",
      "|    0   N/A  N/A    154370      G   ...,262144 --variations-seed-version=1       70MiB |\n",
      "|    0   N/A  N/A    262041      G   ...erProcess --variations-seed-version      102MiB |\n",
      "|    1   N/A  N/A    131351      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A    697602      C   ...niforge3/envs/langchain4/bin/python     7030MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
